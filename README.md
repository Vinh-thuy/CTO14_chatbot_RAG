# DÃ©monstration de Retrieval-Augmented Generation (RAG) avec LLM

## ğŸš€ Introduction

Ce projet est une dÃ©monstration pratique de Retrieval-Augmented Generation (RAG), une technique innovante qui amÃ©liore les capacitÃ©s des modÃ¨les de langage en leur fournissant un contexte supplÃ©mentaire lors de la gÃ©nÃ©ration de rÃ©ponses.

## ğŸ“˜ Concepts ClÃ©s

### Qu'est-ce que le RAG ?
Le RAG combine deux technologies puissantes :
1. **Recherche sÃ©mantique** : Trouver des informations pertinentes dans un document
2. **GÃ©nÃ©ration de texte** : Produire une rÃ©ponse basÃ©e sur ces informations

### Composants Principaux
- **ModÃ¨le de Langage** : `distilgpt2` (version allÃ©gÃ©e de GPT-2)
- **Embeddings** : Transformations vectorielles des documents
- **Base de DonnÃ©es Vectorielle** : ChromaDB pour le stockage et la recherche sÃ©mantique

## ğŸ›  FonctionnalitÃ©s Principales

### 1. Chargement du ModÃ¨le LLM
- TÃ©lÃ©chargement du modÃ¨le `distilgpt2`
- Configuration optimisÃ©e pour les performances
- Gestion intelligente du cache

### 2. Extraction de Texte PDF
- Lecture automatique de documents PDF
- Extraction du contenu textuel

### 3. Indexation SÃ©mantique
- Transformation du texte en vecteurs
- CrÃ©ation d'une base de donnÃ©es vectorielle
- Permet une recherche sÃ©mantique prÃ©cise

### 4. GÃ©nÃ©ration de RÃ©ponses
- Deux modes de gÃ©nÃ©ration :
  1. **Sans Contexte** : RÃ©ponse basique du modÃ¨le
  2. **Avec RAG** : RÃ©ponse enrichie par des informations contextuelles

## ğŸ” Workflow DÃ©taillÃ©

1. **PrÃ©paration**
   - Charger le modÃ¨le de langage
   - Initialiser l'embedder
   - Extraire le texte du PDF

2. **Indexation**
   - Diviser le texte en segments
   - CrÃ©er des embeddings
   - Stocker dans ChromaDB

3. **RequÃªte**
   - L'utilisateur pose une question
   - Recherche sÃ©mantique des passages pertinents
   - GÃ©nÃ©ration de la rÃ©ponse avec contexte

## ğŸ”¬ Architecture Technique DÃ©taillÃ©e

### 1. SystÃ¨me de Logging PersonnalisÃ© ğŸŒˆ

#### Objectif : AmÃ©lioration de la LisibilitÃ©
- **Codes Couleurs PersonnalisÃ©s** :
  - ğŸŸ£ Magenta : Chargement du modÃ¨le Hugging Face
  - ğŸ”µ Bleu : RequÃªtes LLM
  - ğŸŸ¢ Vert : Configuration du RAG
  - ğŸ”· Cyan : RequÃªtes RAG

#### Avantages
- Distinction visuelle des Ã©tapes d'exÃ©cution
- AmÃ©lioration du dÃ©bogage
- ExpÃ©rience utilisateur amÃ©liorÃ©e

### 2. Chargement du ModÃ¨le LLM ğŸ¤–

#### Ã‰tapes Principales
1. **PrÃ©paration du Cache**
   - CrÃ©ation d'un rÃ©pertoire de cache personnalisÃ©
   - Nettoyage du cache existant

2. **Chargement du Tokenizer**
   - Utilisation de `AutoTokenizer`
   - Configuration des tokens spÃ©ciaux
   - Logging dÃ©taillÃ© :
     ```
     ğŸ¤– TÃ©lÃ©chargement du tokenizer...
     âœ… Tokenizer tÃ©lÃ©chargÃ©
     ğŸ“Š Taille du vocabulaire
     ğŸ·ï¸ Tokens spÃ©ciaux
     ```

3. **Optimisations du ModÃ¨le**
   - `device_map='auto'` : SÃ©lection automatique du pÃ©riphÃ©rique
   - `torch_dtype=torch.float16` : RÃ©duction de prÃ©cision
   - `low_cpu_mem_usage=True` : Minimisation de l'utilisation CPU

### 3. GÃ©nÃ©ration de RÃ©ponse ğŸ”

#### StratÃ©gies Intelligentes
- SÃ©lection dynamique du pÃ©riphÃ©rique (CPU/GPU/MPS)
- Tokenization adaptative
- Gestion des erreurs de gÃ©nÃ©ration

### 4. Extraction de Texte PDF ğŸ“„

#### Workflow
1. Ouverture du fichier PDF
2. Lecture sÃ©quentielle des pages
3. ConcatÃ©nation du texte
4. Gestion robuste des erreurs

### 5. Configuration du SystÃ¨me RAG ğŸ—ï¸

#### Processus d'Indexation
1. **PrÃ©paration du Texte**
   - Division en segments intelligents
   - Utilisation de `RecursiveCharacterTextSplitter`

2. **CrÃ©ation d'Embeddings**
   - Transformation vectorielle
   - ModÃ¨le `SentenceTransformer`

3. **Indexation Vectorielle**
   - Collection ChromaDB
   - Stockage des reprÃ©sentations sÃ©mantiques

### 6. RequÃªte RAG Intelligente ğŸ•µï¸

#### Ã‰tapes de Recherche et GÃ©nÃ©ration
1. Embedding de la requÃªte utilisateur
2. Recherche sÃ©mantique dans ChromaDB
3. RÃ©cupÃ©ration des passages contextuels
4. GÃ©nÃ©ration de rÃ©ponse enrichie

### 7. Comparaison Analytique ğŸ”¬

#### Objectif : Ã‰valuation Comparative
- Comparaison des rÃ©ponses :
  1. Sans contexte RAG
  2. Avec contexte RAG
- Mesure de la valeur ajoutÃ©e du RAG

### Principes de Conception ğŸ¯

#### Approche Technique
- **ModularitÃ©** : ResponsabilitÃ©s uniques par fonction
- **Logging Exhaustif** : TraÃ§abilitÃ© complÃ¨te
- **AdaptabilitÃ©** : Configuration dynamique
- **Performance** : Optimisation des ressources

### Points Techniques AvancÃ©s ğŸš€

- AccÃ©lÃ©ration GPU avec `torch`
- Gestion dynamique des pÃ©riphÃ©riques
- Logging colorÃ© et informatif
- Embeddings sÃ©mantiques avancÃ©s
- Recherche contextuelle intelligente

### Limitations Actuelles ğŸš§

- ModÃ¨le lÃ©ger (`distilgpt2`)
- Performances pour tÃ¢ches complexes
- DÃ©pendance Ã  la qualitÃ© du document source

## ğŸ”® Perspectives d'AmÃ©lioration

1. IntÃ©gration de modÃ¨les plus performants
2. AmÃ©lioration de la recherche sÃ©mantique
3. DÃ©veloppement de mÃ©triques d'Ã©valuation
4. Support multi-documents
5. Interface utilisateur plus intuitive

## ğŸ’» PrÃ©requis Techniques

- Python 3.8+
- BibliothÃ¨ques :
  - `torch`
  - `transformers`
  - `chromadb`
  - `sentence-transformers`
  - `PyPDF2`

## ğŸš¦ Comment Utiliser

1. Installez les dÃ©pendances :
   ```bash
   pip install -r requirements.txt
   ```

2. PrÃ©parez un fichier PDF

3. Lancez la dÃ©monstration :
   ```bash
   python llm_rag_demo.py
   ```

## ğŸ“ Pour les DÃ©butants

- **ModÃ¨le de Langage** : Un "assistant" qui gÃ©nÃ¨re du texte
- **Embedding** : Transformer du texte en "coordonnÃ©es" pour la recherche
- **SÃ©mantique** : Comprendre le sens, pas juste les mots

## ğŸ”¬ Points Techniques AvancÃ©s

- Utilisation de `torch` pour l'accÃ©lÃ©ration GPU
- Gestion dynamique du pÃ©riphÃ©rique (CPU/GPU)
- Logging colorÃ© pour une meilleure lisibilitÃ©

## ğŸš§ Limitations

- ModÃ¨le lÃ©ger (`distilgpt2`)
- Performances limitÃ©es pour des tÃ¢ches complexes
- NÃ©cessite un bon document source

## ğŸ¤ Contributions

N'hÃ©sitez pas Ã  ouvrir des issues ou proposer des amÃ©liorations !

## ğŸ“œ Licence

[SpÃ©cifiez votre licence]

## ğŸŒ API Flask avec Swagger

### FonctionnalitÃ©s de l'API

#### 1. GÃ©nÃ©ration de Texte `/generate`
- **MÃ©thode** : POST
- **Description** : GÃ©nÃ©rer du texte avec le modÃ¨le LLM
- **ParamÃ¨tres** :
  - `prompt` (requis) : Texte de dÃ©part pour la gÃ©nÃ©ration

#### 2. RequÃªte RAG `/rag_query`
- **MÃ©thode** : POST
- **Description** : Effectuer une recherche sÃ©mantique avec RAG
- **ParamÃ¨tres** :
  - `query` (requis) : Question ou requÃªte pour la recherche

### DÃ©marrage de l'API

1. Installer les dÃ©pendances :
   ```bash
   pip install -r requirements.txt
   ```

2. Lancer l'API :
   ```bash
   python app.py
   ```

3. AccÃ©der Ã  la documentation Swagger :
   - URL : `http://localhost:5000/apidocs/`

### Exemple de RequÃªte cURL

#### GÃ©nÃ©ration de Texte
```bash
curl -X POST http://localhost:5000/generate \
     -H "Content-Type: application/json" \
     -d '{"prompt": "Explique le machine learning"}'
```

#### RequÃªte RAG
```bash
curl -X POST http://localhost:5000/rag_query \
     -H "Content-Type: application/json" \
     -d '{"query": "Qu'est-ce que le RAG ?"}'
```

### DÃ©ploiement

- Serveur de production recommandÃ© : Gunicorn
- Commande de dÃ©marrage :
  ```bash
  gunicorn -w 4 -b 0.0.0.0:5000 app:app
  ```

### SÃ©curitÃ© et Configuration

- Mode debug dÃ©sactivÃ© en production
- Configuration CORS si nÃ©cessaire
- Ajout potentiel d'authentification
